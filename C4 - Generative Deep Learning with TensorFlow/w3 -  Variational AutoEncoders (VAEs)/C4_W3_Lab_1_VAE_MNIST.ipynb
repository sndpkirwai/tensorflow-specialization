{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C4_W3_Lab_1_VAE_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "416c1e8c2665456c9c22eb5a25d437d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_318896715df84cbeb427c9e9e470a5f9",
              "IPY_MODEL_4cb99d4b42424a329330ea8c3626e538",
              "IPY_MODEL_a5fff4fee6164914a12ab657239e2ae4"
            ],
            "layout": "IPY_MODEL_3312313766184c618346620e8b15ec2b"
          }
        },
        "318896715df84cbeb427c9e9e470a5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48995f9146e4df180706f5adb61a438",
            "placeholder": "​",
            "style": "IPY_MODEL_cff809ca6598482587e8c21409bafcc7",
            "value": "Dl Completed...: 100%"
          }
        },
        "4cb99d4b42424a329330ea8c3626e538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6103b9d9485e4f789acf6156836101c2",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcae8835f7e245dea1d2ea04703dbf16",
            "value": 4
          }
        },
        "a5fff4fee6164914a12ab657239e2ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0139927121145b28f4e5e5586c8f220",
            "placeholder": "​",
            "style": "IPY_MODEL_bf0794dc51f44b07afc1f1f1d7cf6000",
            "value": " 4/4 [00:00&lt;00:00, 13.47 file/s]"
          }
        },
        "3312313766184c618346620e8b15ec2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e48995f9146e4df180706f5adb61a438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff809ca6598482587e8c21409bafcc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6103b9d9485e4f789acf6156836101c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcae8835f7e245dea1d2ea04703dbf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0139927121145b28f4e5e5586c8f220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0794dc51f44b07afc1f1f1d7cf6000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2m-t1vpjAMj"
      },
      "source": [
        "# Ungraded Lab: Variational Autoencoders\n",
        "\n",
        "This lab will demonstrate all the concepts you learned this week. You will build a Variational Autoencoder (VAE) trained on the MNIST dataset and see how it is able to generate new images. This will be very useful for this week's assignment. Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dE3sNy_jKus"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17DD2aRgudaO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGHahainjOji"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBoDTLNXuFqT"
      },
      "source": [
        "# Define global constants to be used in this notebook\n",
        "BATCH_SIZE=128\n",
        "LATENT_DIM=2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqZ-LiQbjaNX"
      },
      "source": [
        "## Prepare the Dataset\n",
        "\n",
        "You will just be using the `train` split of the MNIST dataset in this notebook. We've prepared a few helper functions below to help in downloading and preparing the dataset:\n",
        "\n",
        "* `map_image()` - normalizes and creates a tensor from the image, returning only the image. This will be used for the unsupervised learning in the autoencoder.\n",
        "\n",
        "* `get_dataset()` - loads MNIST from Tensorflow Datasets, fetching the `train` split by default, then prepares it using the mapping function. If `is_validation` is set to `True`, then it will get the `test` split instead. Training sets will also be shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgPMPNbteYU"
      },
      "source": [
        "def map_image(image, label):\n",
        "  '''returns a normalized and reshaped tensor from a given image'''\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image, shape=(28, 28, 1,))\n",
        "  \n",
        "  return image\n",
        "\n",
        "\n",
        "def get_dataset(map_fn, is_validation=False):\n",
        "  '''Loads and prepares the mnist dataset from TFDS.'''\n",
        "  if is_validation:\n",
        "    split_name = \"test\"\n",
        "  else:\n",
        "    split_name = \"train\"\n",
        "\n",
        "  dataset = tfds.load('mnist', as_supervised=True, split=split_name)\n",
        "  dataset = dataset.map(map_fn)\n",
        "  \n",
        "  if is_validation:\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    dataset = dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttCP6xrJGxY5"
      },
      "source": [
        "Please run this cell to download and prepare the `train` split of the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jszTpjHVuJXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "416c1e8c2665456c9c22eb5a25d437d5",
            "318896715df84cbeb427c9e9e470a5f9",
            "4cb99d4b42424a329330ea8c3626e538",
            "a5fff4fee6164914a12ab657239e2ae4",
            "3312313766184c618346620e8b15ec2b",
            "e48995f9146e4df180706f5adb61a438",
            "cff809ca6598482587e8c21409bafcc7",
            "6103b9d9485e4f789acf6156836101c2",
            "fcae8835f7e245dea1d2ea04703dbf16",
            "a0139927121145b28f4e5e5586c8f220",
            "bf0794dc51f44b07afc1f1f1d7cf6000"
          ]
        },
        "outputId": "cd951d03-fd61-4de7-f0d0-380c0cc28c74"
      },
      "source": [
        "train_dataset = get_dataset(map_image)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "416c1e8c2665456c9c22eb5a25d437d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qedUCLa_jfeM"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "You will now be building your VAE model. The main parts are shown in the figure below:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1YAZAeMGEJ1KgieYk1ju-S9DoshpMREeC\" width=\"60%\" height=\"60%\"/>\n",
        "\n",
        "Like the autoencoder last week, the VAE also has an encoder-decoder architecture with the main difference being the grey box in the middle which stands for the latent representation. In this layer, the model mixes a random sample and combines it with the outputs of the encoder. This mechanism makes it useful for generating new content. Let's build these parts one-by-one in the next sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaj1dg-FrWuG"
      },
      "source": [
        "### Sampling Class\n",
        "\n",
        "First, you will build the `Sampling` class. This will be a custom Keras layer that will provide the Gaussian noise input along with the mean (mu) and standard deviation (sigma) of the encoder's output. In practice, the output of this layer is given by the equation:\n",
        "\n",
        "$$z = \\mu + e^{0.5\\sigma} * \\epsilon  $$\n",
        "\n",
        "where $\\mu$ = mean, $\\sigma$ = standard deviation, and $\\epsilon$ = random sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLApb2VuzKZ"
      },
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    \"\"\"Generates a random sample and combines with the encoder output\n",
        "    \n",
        "    Args:\n",
        "      inputs -- output tensor from the encoder\n",
        "\n",
        "    Returns:\n",
        "      `inputs` tensors combined with a random sample\n",
        "    \"\"\"\n",
        "\n",
        "    # unpack the output of the encoder\n",
        "    mu, sigma = inputs\n",
        "\n",
        "    # get the size and dimensions of the batch\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "\n",
        "    # generate a random tensor\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "\n",
        "    # combine the inputs and noise\n",
        "    return mu + tf.exp(0.5 * sigma) * epsilon"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCqWbPNvrplb"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "Next, you will build the encoder part of the network. You will follow the architecture shown in class which looks like this. Note that aside from mu and sigma, you will also output the shape of features before flattening it. This will be useful when reconstructing the image later in the decoder.\n",
        "\n",
        "*Note:* You might encounter issues with using batch normalization with smaller batches, and sometimes the advice is given to avoid using batch normalization when training VAEs in particular. Feel free to experiment with adding or removing it from this notebook to explore the effects.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1eoxFK_UVSHd3a_5EHcCU8F8QDZlPiXfW\" width=\"60%\" height=\"60%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5kZsj0u9jX"
      },
      "source": [
        "def encoder_layers(inputs, latent_dim):\n",
        "  \"\"\"Defines the encoder's layers.\n",
        "  Args:\n",
        "    inputs -- batch from the dataset\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "\n",
        "  Returns:\n",
        "    mu -- learned mean\n",
        "    sigma -- learned standard deviation\n",
        "    batch_2.shape -- shape of the features before flattening\n",
        "  \"\"\"\n",
        "\n",
        "  # add the Conv2D layers followed by BatchNormalization\n",
        "  x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation='relu', name=\"encode_conv1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"encode_conv2\")(x)\n",
        "\n",
        "  # assign to a different variable so you can extract the shape later\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # flatten the features and feed into the Dense network\n",
        "  x = tf.keras.layers.Flatten(name=\"encode_flatten\")(batch_2)\n",
        "\n",
        "  # we arbitrarily used 20 units here but feel free to change and see what results you get\n",
        "  x = tf.keras.layers.Dense(20, activation='relu', name=\"encode_dense\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # add output Dense networks for mu and sigma, units equal to the declared latent_dim.\n",
        "  mu = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim, name ='latent_sigma')(x)\n",
        "\n",
        "  return mu, sigma, batch_2.shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFiOzFnUnPMN"
      },
      "source": [
        "With the encoder layers defined, you can declare the encoder model that includes the `Sampling` layer with the function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoLLpfBUvhBm"
      },
      "source": [
        "def encoder_model(latent_dim, input_shape):\n",
        "  \"\"\"Defines the encoder model with the Sampling layer\n",
        "  Args:\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "    input_shape -- shape of the dataset batch\n",
        "\n",
        "  Returns:\n",
        "    model -- the encoder model\n",
        "    conv_shape -- shape of the features before flattening\n",
        "  \"\"\"\n",
        "\n",
        "  # declare the inputs tensor with the given shape\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "  # get the output of the encoder_layers() function\n",
        "  mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=LATENT_DIM)\n",
        "\n",
        "  # feed mu and sigma to the Sampling layer\n",
        "  z = Sampling()((mu, sigma))\n",
        "\n",
        "  # build the whole encoder model\n",
        "  model = tf.keras.Model(inputs, outputs=[mu, sigma, z])\n",
        "\n",
        "  return model, conv_shape"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkFgN22trttX"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Next, you will build the decoder part of the network which expands the latent representations back to the original image dimensions. As you'll see later in the training loop, you can feed random inputs to this model and it will generate content that resemble the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H_HoaAYvWZn"
      },
      "source": [
        "def decoder_layers(inputs, conv_shape):\n",
        "  \"\"\"Defines the decoder layers.\n",
        "  Args:\n",
        "    inputs -- output of the encoder \n",
        "    conv_shape -- shape of the features before flattening\n",
        "\n",
        "  Returns:\n",
        "    tensor containing the decoded output\n",
        "  \"\"\"\n",
        "\n",
        "  # feed to a Dense network with units computed from the conv_shape dimensions\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layers.Dense(units, activation = 'relu', name=\"decode_dense1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  \n",
        "  # reshape output using the conv_shape dimensions\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name=\"decode_reshape\")(x)\n",
        "\n",
        "  # upsample the features back to the original dimensions\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d_2\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d_3\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid', name=\"decode_final\")(x)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX2hjxYhxQyn"
      },
      "source": [
        "You can define the decoder model as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGZ5kqA4vuEy"
      },
      "source": [
        "def decoder_model(latent_dim, conv_shape):\n",
        "  \"\"\"Defines the decoder model.\n",
        "  Args:\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "    conv_shape -- shape of the features before flattening\n",
        "\n",
        "  Returns:\n",
        "    model -- the decoder model\n",
        "  \"\"\"\n",
        "\n",
        "  # set the inputs to the shape of the latent space\n",
        "  inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "\n",
        "  # get the output of the decoder layers\n",
        "  outputs = decoder_layers(inputs, conv_shape)\n",
        "\n",
        "  # declare the inputs and outputs of the model\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQbtaVsHrxQ_"
      },
      "source": [
        "### Kullback–Leibler Divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqG6oUC3r6Um"
      },
      "source": [
        "To improve the generative capability of the model, you have to take into account the random normal distribution introduced in the latent space. For that, the [Kullback–Leibler Divergence](https://arxiv.org/abs/2002.07514) is computed and added to the reconstruction loss. The formula is defined in the function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Gla4K6vcLN"
      },
      "source": [
        "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
        "  \"\"\" Computes the Kullback-Leibler Divergence (KLD)\n",
        "  Args:\n",
        "    inputs -- batch from the dataset\n",
        "    outputs -- output of the Sampling layer\n",
        "    mu -- mean\n",
        "    sigma -- standard deviation\n",
        "\n",
        "  Returns:\n",
        "    KLD loss\n",
        "  \"\"\"\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  kl_loss = tf.reduce_mean(kl_loss) * -0.5\n",
        "\n",
        "  return kl_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiAwutTjr6aQ"
      },
      "source": [
        "### VAE Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymQdQTOJvOTR"
      },
      "source": [
        "You can now define the entire VAE model. Note the use of `model.add_loss()` to add the KL reconstruction loss. Computing this loss doesn't use `y_true` and `y_pred` so it can't be used in `model.compile()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hkx7OCqvzlb"
      },
      "source": [
        "def vae_model(encoder, decoder, input_shape):\n",
        "  \"\"\"Defines the VAE model\n",
        "  Args:\n",
        "    encoder -- the encoder model\n",
        "    decoder -- the decoder model\n",
        "    input_shape -- shape of the dataset batch\n",
        "\n",
        "  Returns:\n",
        "    the complete VAE model\n",
        "  \"\"\"\n",
        "\n",
        "  # set the inputs\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "  # get mu, sigma, and z from the encoder output\n",
        "  mu, sigma, z = encoder(inputs)\n",
        "  \n",
        "  # get reconstructed output from the decoder\n",
        "  reconstructed = decoder(z)\n",
        "\n",
        "  # define the inputs and outputs of the VAE\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n",
        "\n",
        "  # add the KL loss\n",
        "  loss = kl_reconstruction_loss(inputs, z, mu, sigma)\n",
        "  model.add_loss(loss)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5FxUuopxa_I"
      },
      "source": [
        "We'll add a helper function to setup and get the different models from the functions you defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piqZLzkHv3jw"
      },
      "source": [
        "def get_models(input_shape, latent_dim):\n",
        "  \"\"\"Returns the encoder, decoder, and vae models\"\"\"\n",
        "  encoder, conv_shape = encoder_model(latent_dim=latent_dim, input_shape=input_shape)\n",
        "  decoder = decoder_model(latent_dim=latent_dim, conv_shape=conv_shape)\n",
        "  vae = vae_model(encoder, decoder, input_shape=input_shape)\n",
        "  return encoder, decoder, vae"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOp-yWg2v7uP"
      },
      "source": [
        "# Get the encoder, decoder and 'master' model (called vae)\n",
        "encoder, decoder, vae = get_models(input_shape=(28,28,1,), latent_dim=LATENT_DIM)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLMU6YySmWKR"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHVaw_kqyPQI"
      },
      "source": [
        "You can now setup the VAE model for training. Let's start by defining the reconstruction loss, optimizer and metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWqvQqvwEMK"
      },
      "source": [
        "# Define our loss functions and optimizers\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpmZiTYQzIVH"
      },
      "source": [
        "You will want to see the progress of the image generation at each epoch. For that, you can use the helper function below. This will generate 16 images in a 4x4 grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaG0h17cwUYM"
      },
      "source": [
        "def generate_and_save_images(model, epoch, step, test_input):\n",
        "  \"\"\"Helper function to plot our 16 images\n",
        "\n",
        "  Args:\n",
        "\n",
        "  model -- the decoder model\n",
        "  epoch -- current epoch number during training\n",
        "  step -- current step number during training\n",
        "  test_input -- random tensor with shape (16, LATENT_DIM)\n",
        "  \"\"\"\n",
        "\n",
        "  # generate images from the test input\n",
        "  predictions = model.predict(test_input)\n",
        "\n",
        "  # plot the results\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\n",
        "  fig.suptitle(\"epoch: {}, step: {}\".format(epoch, step))\n",
        "  plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))\n",
        "  plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeArnhVI0HQx"
      },
      "source": [
        "The training loop is shown below. This will display generated images each epoch and will take around 30 minutes to complete. Notice too that we add the KLD loss to the binary crossentropy loss before we get the gradients and update the weights.\n",
        "\n",
        "As you might expect, the initial 16 images will look random but it will improve overtime as the network learns and you'll see images that resemble the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8o4ZPU1wSFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "4299ecc8-cb30-4e17-bd1f-c4606f1a7518"
      },
      "source": [
        "# Training loop. \n",
        "\n",
        "# generate random vector as test input to the decoder\n",
        "random_vector_for_generation = tf.random.normal(shape=[16, LATENT_DIM])\n",
        "\n",
        "# number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# initialize the helper function to display outputs from an untrained model\n",
        "generate_and_save_images(decoder, 0, 0, random_vector_for_generation)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # iterate over the batches of the dataset.\n",
        "  for step, x_batch_train in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # feed a batch to the VAE model\n",
        "      reconstructed = vae(x_batch_train)\n",
        "\n",
        "      # compute reconstruction loss\n",
        "      flattened_inputs = tf.reshape(x_batch_train, shape=[-1])\n",
        "      flattened_outputs = tf.reshape(reconstructed, shape=[-1])\n",
        "      loss = bce_loss(flattened_inputs, flattened_outputs) * 784\n",
        "      \n",
        "      # add KLD regularization loss\n",
        "      loss += sum(vae.losses)  \n",
        "\n",
        "    # get the gradients and update the weights\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    # compute the loss metric\n",
        "    loss_metric(loss)\n",
        "\n",
        "    # display outputs every 100 steps\n",
        "    if step % 100 == 0:\n",
        "      display.clear_output(wait=False)    \n",
        "      generate_and_save_images(decoder, epoch, step, random_vector_for_generation)\n",
        "      print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result().numpy()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 step: 100 mean loss = 153.23296\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7981a06600b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m# feed a batch to the VAE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m# compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           outputs = tf.nn.bias_add(\n\u001b[0;32m--> 267\u001b[0;31m               outputs, self.bias, data_format=self._tf_data_format)\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3508\u001b[0m   \"\"\"\n\u001b[0;32m-> 3509\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3510\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6715\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6716\u001b[0m   \"\"\"\n\u001b[0;32m-> 6717\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6718\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minternal_name_scope_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;34m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mones_rank_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrQB8Lr919hn"
      },
      "source": [
        "**Congratulations on completing this lab on Variational Autoencoders!**"
      ]
    }
  ]
}